bert_base_unfreeze0 Epoch 1/40: 100%|█| 39/39 [00:02<00
✅ Epoch 1 | Loss=1.4614 | F1=0.247
bert_base_unfreeze0 Epoch 2/40: 100%|█| 39/39 [00:02<00
✅ Epoch 2 | Loss=1.4314 | F1=0.253
bert_base_unfreeze0 Epoch 3/40: 100%|█| 39/39 [00:02<00
✅ Epoch 3 | Loss=1.4103 | F1=0.248
bert_base_unfreeze0 Epoch 4/40: 100%|█| 39/39 [00:02<00
✅ Epoch 4 | Loss=1.3874 | F1=0.252
bert_base_unfreeze0 Epoch 5/40: 100%|█| 39/39 [00:02<00
✅ Epoch 5 | Loss=1.3671 | F1=0.256
bert_base_unfreeze0 Epoch 6/40: 100%|█| 39/39 [00:02<00
✅ Epoch 6 | Loss=1.3507 | F1=0.261
bert_base_unfreeze0 Epoch 7/40: 100%|█| 39/39 [00:02<00
✅ Epoch 7 | Loss=1.3405 | F1=0.261
bert_base_unfreeze0 Epoch 8/40: 100%|█| 39/39 [00:02<00
✅ Epoch 8 | Loss=1.3301 | F1=0.266
bert_base_unfreeze0 Epoch 9/40: 100%|█| 39/39 [00:02<00
✅ Epoch 9 | Loss=1.3149 | F1=0.266
bert_base_unfreeze0 Epoch 10/40: 100%|█| 39/39 [00:02<0
✅ Epoch 10 | Loss=1.3020 | F1=0.272
bert_base_unfreeze0 Epoch 11/40: 100%|█| 39/39 [00:02<0
✅ Epoch 11 | Loss=1.2900 | F1=0.283
bert_base_unfreeze0 Epoch 12/40:  18%|▏| 7/39 [00:00<00
Traceback (most recent call last):
  File "/home/700050058/project_feedback_analyzer/training_multitask.py", line 255, in <module>
    result = run_experiment(cfg)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/700050058/project_feedback_analyzer/training_multitask.py", line 208, in run_experiment
    train_loss, val_f1 = train_model(model, train_loader, val_loader, optimizer, scheduler, loss_fn, cfg)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/700050058/project_feedback_analyzer/training_multitask.py", line 139, in train_model
    for batch in tqdm(train_loader, desc=f"{cfg['exp_name']} Epoch {epoch+1}/{cfg['epochs']}"):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/700050058/.conda/envs/fastvideo/lib/python3.12/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
               ^^^^^^^^
  File "/home/700050058/.conda/envs/fastvideo/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/700050058/.conda/envs/fastvideo/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 789, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/700050058/.conda/envs/fastvideo/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/700050058/project_feedback_analyzer/training_multitask.py", line 38, in __getitem__
    tokens = self.tokenizer(
             ^^^^^^^^^^^^^^^
  File "/home/700050058/.conda/envs/fastvideo/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2938, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/700050058/.conda/envs/fastvideo/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 3048, in _call_one
    return self.encode_plus(
           ^^^^^^^^^^^^^^^^^
  File "/home/700050058/.conda/envs/fastvideo/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 3123, in encode_plus
    return self._encode_plus(
           ^^^^^^^^^^^^^^^^^^
  File "/home/700050058/.conda/envs/fastvideo/lib/python3.12/site-packages/transformers/tokenization_utils.py", line 800, in _encode_plus
    first_ids = get_input_ids(text)
                ^^^^^^^^^^^^^^^^^^^
  File "/home/700050058/.conda/envs/fastvideo/lib/python3.12/site-packages/transformers/tokenization_utils.py", line 767, in get_input_ids
    tokens = self.tokenize(text, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/700050058/.conda/envs/fastvideo/lib/python3.12/site-packages/transformers/tokenization_utils.py", line 697, in tokenize
    tokenized_text.extend(self._tokenize(token))
                          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/700050058/.conda/envs/fastvideo/lib/python3.12/site-packages/transformers/models/bert/tokenization_bert.py", line 161, in _tokenize
    for token in self.basic_tokenizer.tokenize(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/700050058/.conda/envs/fastvideo/lib/python3.12/site-packages/transformers/models/bert/tokenization_bert.py", line 327, in tokenize
    token = token.lower()
            ^^^^^^^^^^^^^
KeyboardInterrupt
